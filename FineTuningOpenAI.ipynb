{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rjRYWAXXr8KR"
      },
      "outputs": [],
      "source": [
        "# !pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "2SBoaxhBr9Nl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZk2nFx0sEh2",
        "outputId": "32e30ccc-eb68-4ddb-8c3e-703601e0b5a0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a great philosopher.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}\n",
        "  ]\n",
        ")\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Ko7dLQtd0lwt",
        "outputId": "2e491141-0fc2-41bf-b12e-af26a75d0abe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The meaning of life is a profound question that has been contemplated by philosophers, theologians, and thinkers throughout history. Different perspectives offer various interpretations:\n\n1. **Existentialism**: This viewpoint, associated with philosophers like Jean-Paul Sartre and Albert Camus, suggests that life has no inherent meaning, and it is up to individuals to create their own purpose through choices and actions.\n\n2. **Religious Perspectives**: Many religious traditions propose that the meaning of life is defined by a connection to the divine, moral conduct, and the pursuit of spiritual fulfillment. For instance, in Christianity, the purpose of life might be seen as serving God and practicing love and compassion toward others.\n\n3. **Humanism**: From a humanistic standpoint, the meaning of life can be found in the pursuit of knowledge, the cultivation of relationships, and the betterment of society. Humanists often emphasize the importance of human experiences, emotions, and ethics.\n\n4. **Buddhism**: In Buddhist philosophy, life is often viewed through the lens of suffering and the quest for enlightenment. The meaning of life may involve recognizing and transcending suffering through practices like mindfulness and compassion.\n\n5. **Scientific Perspective**: Some may argue that from a biological standpoint, the meaning of life is to survive and reproduce, ensuring the continuation of our species.\n\nUltimately, the meaning of life can be a deeply personal journey. It may vary significantly from one individual to another, shaped by personal experiences, beliefs, and aspirations. Finding meaning often involves exploration, introspection, and engagement with the world around us."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CSV file with the correct delimiter\n",
        "file_path = '/content/drive/MyDrive/Reddit_Title.csv'  # Change this to your local path\n",
        "data = pd.read_csv(file_path, sep=';')\n",
        "\n",
        "# Clean up and drop unnecessary columns, and select the top 200 rows\n",
        "data_cleaned = data[['title', 'label']].head(200)\n",
        "\n",
        "# Mapping the 'label' column to more human-readable text\n",
        "label_mapping = {0: \"non-stress\", 1: \"stress\"}\n",
        "data_cleaned['label'] = data_cleaned['label'].map(label_mapping)\n",
        "\n",
        "# Split the data into training and validation sets (80% train, 20% validation)\n",
        "train_data, validation_data = train_test_split(data_cleaned, test_size=0.2, random_state=42)\n",
        "\n",
        "def save_to_jsonl(data, output_file_path):\n",
        "    jsonl_data = []\n",
        "    for index, row in data.iterrows():\n",
        "        jsonl_data.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": \"Given a social media post, classify whether it indicates 'stress' or 'non-stress'.\"},\n",
        "                {\"role\": \"user\", \"content\": row['title']},\n",
        "                {\"role\": \"assistant\", \"content\": f\"\\\"{row['label']}\\\"\"}\n",
        "            ]\n",
        "        })\n",
        "\n",
        "    # Save to JSONL format\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        for item in jsonl_data:\n",
        "            f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "# Save the training and validation sets to separate JSONL files\n",
        "train_output_file_path = 'stress_detection_train.jsonl'\n",
        "validation_output_file_path = 'stress_detection_validation.jsonl'\n",
        "\n",
        "save_to_jsonl(train_data, train_output_file_path)\n",
        "save_to_jsonl(validation_data, validation_output_file_path)\n",
        "\n",
        "print(f\"Training dataset save to {train_output_file_path}\")\n",
        "print(f\"Validation dataset save to {validation_output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ_w0mDG0w8a",
        "outputId": "2e7b0778-6e15-4ba0-a1df-e29e881bf3fa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset save to stress_detection_train.jsonl\n",
            "Validation dataset save to stress_detection_validation.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = client.files.create(\n",
        "  file=open(train_output_file_path, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "valid_file = client.files.create(\n",
        "  file=open(validation_output_file_path, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(f\"Training file Info: {train_file}\")\n",
        "print(f\"Validation file Info: {valid_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpeOZAf00-AJ",
        "outputId": "db1dc5c3-a2ea-496c-e6c8-e8650b2d106f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training file Info: FileObject(id='file-3XuhnuqiXdUoTZsyblphNNaY', bytes=50323, created_at=1731238031, filename='stress_detection_train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
            "Validation file Info: FileObject(id='file-wFus99DwtDaaZFxjYqjd7QqZ', bytes=12724, created_at=1731238031, filename='stress_detection_validation.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = client.fine_tuning.jobs.create(\n",
        "  training_file=train_file.id,\n",
        "  validation_file=valid_file.id,\n",
        "  model=\"gpt-4o-mini-2024-07-18\",\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 3,\n",
        "\t\"batch_size\": 3,\n",
        "\t\"learning_rate_multiplier\": 0.3\n",
        "  }\n",
        ")\n",
        "job_id = model.id\n",
        "status = model.status\n",
        "\n",
        "print(f'Fine-tuning model with jobID: {job_id}.')\n",
        "print(f\"Training Response: {model}\")\n",
        "print(f\"Training Status: {status}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNJLpT-1BRM",
        "outputId": "90934078-d90f-4770-c596-7975af9b1dcd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning model with jobID: ftjob-LJ7VG3rROwBD4ZwcPEnleiBO.\n",
            "Training Response: FineTuningJob(id='ftjob-LJ7VG3rROwBD4ZwcPEnleiBO', created_at=1731238047, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=0.3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-PB66izrMdR2HiHnmerl1U9WY', result_files=[], seed=1464939079, status='validating_files', trained_tokens=None, training_file='file-3XuhnuqiXdUoTZsyblphNNaY', validation_file='file-wFus99DwtDaaZFxjYqjd7QqZ', estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Training Status: validating_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune\n",
        "client.fine_tuning.jobs.retrieve(job_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-JbLbyj1GXi",
        "outputId": "1d2805e5-9bf7-43c7-9413-14bedffa6b05"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-LJ7VG3rROwBD4ZwcPEnleiBO', created_at=1731238047, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=0.3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-PB66izrMdR2HiHnmerl1U9WY', result_files=[], seed=1464939079, status='validating_files', trained_tokens=None, training_file='file-3XuhnuqiXdUoTZsyblphNNaY', validation_file='file-wFus99DwtDaaZFxjYqjd7QqZ', estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = client.fine_tuning.jobs.list()\n",
        "\n",
        "# Retrieve the fine tuned model\n",
        "fine_tuned_model = result.data[0].fine_tuned_model\n",
        "print(fine_tuned_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5vFgIl81Pie",
        "outputId": "2ef7698b-8c8b-439f-f0dc-75deb75c16ae"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ft:gpt-4o-mini-2024-07-18:personal::AS0ZE3Pv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model = fine_tuned_model,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Given a social media post, classify whether it indicates 'stress' or 'non-stress'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Just went to my first homecoming, and they played a song I've always wanted to dance to at an official dance. Sorry for the terrible quality, but my happiness in this moment couldn't be exaggerated!\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMUXeWREu6GK",
        "outputId": "be2c0664-907e-48ee-f850-429a339ab4a4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"non-stress\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test, model):\n",
        "    y_pred = []\n",
        "    categories = [\"non-stress\", \"stress\"]\n",
        "\n",
        "    for index, row in test.iterrows():\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"Given a social media post, classify whether it indicates 'stress' or 'non-stress'.\",\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": row[\"title\"]},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content\n",
        "\n",
        "        # Determine the predicted category\n",
        "\n",
        "        for category in categories:\n",
        "            if category.lower() in answer.lower():\n",
        "                y_pred.append(category)\n",
        "                break\n",
        "        else:\n",
        "            y_pred.append(\"none\")\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "UrLVgjEW4E5j"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    labels = [\"non-stress\", \"stress\"]\n",
        "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "    def map_func(x):\n",
        "        return mapping.get(\n",
        "            x, -1\n",
        "        )  # Map to -1 if not found, but should not occur with correct data\n",
        "\n",
        "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
        "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
        "\n",
        "    # Calculate accuracy\n",
        "\n",
        "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
        "    print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "    # Generate accuracy report\n",
        "\n",
        "    unique_labels = set(y_true_mapped)  # Get unique labels\n",
        "\n",
        "    for label in unique_labels:\n",
        "        label_indices = [\n",
        "            i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label\n",
        "        ]\n",
        "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
        "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
        "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
        "        print(f\"Accuracy for label {labels[label]}: {label_accuracy:.3f}\")\n",
        "    # Generate classification report\n",
        "\n",
        "    class_report = classification_report(\n",
        "        y_true=y_true_mapped,\n",
        "        y_pred=y_pred_mapped,\n",
        "        target_names=labels,\n",
        "        labels=list(range(len(labels))),\n",
        "    )\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(class_report)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "\n",
        "    conf_matrix = confusion_matrix(\n",
        "        y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels)))\n",
        "    )\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "AnphlN0g4J1r"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(validation_data, \"gpt-4o-mini-2024-07-18\")\n",
        "y_true = validation_data[\"label\"]\n",
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpLlCSQg4Mbr",
        "outputId": "f72b94fc-f422-41b0-8983-be722db7f79e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.950\n",
            "Accuracy for label non-stress: 1.000\n",
            "Accuracy for label stress: 0.905\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  non-stress       0.90      1.00      0.95        19\n",
            "      stress       1.00      0.90      0.95        21\n",
            "\n",
            "    accuracy                           0.95        40\n",
            "   macro avg       0.95      0.95      0.95        40\n",
            "weighted avg       0.95      0.95      0.95        40\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19  0]\n",
            " [ 2 19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(validation_data,fine_tuned_model)\n",
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFLZ_IEY4Qhr",
        "outputId": "22f3b2b6-9a81-48c1-a52e-46e337b40497"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.000\n",
            "Accuracy for label non-stress: 1.000\n",
            "Accuracy for label stress: 1.000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  non-stress       1.00      1.00      1.00        19\n",
            "      stress       1.00      1.00      1.00        21\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19  0]\n",
            " [ 0 21]]\n"
          ]
        }
      ]
    }
  ]
}